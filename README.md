# CoreML-Demo
## What is does?
This app demostrates the new framework for Machine Learning by Apple called CoreML. 
<br><br>
It basically determines dominant objects in the scene from thousands of categories such as people, trees, vehicles etc.<br>

The app works simply by tapping to capture a photo, passing it through the CoreML model, and determining the object based on the confidence level.<br>

Additionally, it also speaks up the object determined, with the idea of helping the blind or people with poor vision to determine things.<br>

The app uses a simple open source CoreML model called as [SqueezeNet](https://github.com/DeepScale/SqueezeNet)
<br><br>
Screenshots : 

<br>

## Author
Bhagat Singh <br>
<ul>
<li>Testing Device - iPhone 7 </li>
<li>Testing Firmware iOS 11.2 </li>
<li>Xcode Version - v9.2 Beta </li>
</ul>

License
=======

    Copyright 2017 Bhagat Singh

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

